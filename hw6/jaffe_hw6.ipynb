{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate image features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import namedtuple\n",
    "\n",
    "imgTuple = namedtuple('imgTuple', ['file', 'img_class', 'img_dir'])\n",
    "\n",
    "data_dir = '../../downloads/hw6_data/'\n",
    "\n",
    "def get_immediate_subdirectories(some_dir):\n",
    "    return [name for name in os.listdir(some_dir)\n",
    "           if os.path.isdir(os.path.join(some_dir, name))]\n",
    "\n",
    "categories = get_immediate_subdirectories(data_dir)\n",
    "\n",
    "f0 = os.listdir(os.path.join(data_dir, categories[4]))[0]\n",
    "f0_path = os.path.join(data_dir, categories[4]) + '/' + f0\n",
    "\n",
    "n_categories = 20\n",
    "n_images_per_category = 10\n",
    "\n",
    "imgs = []\n",
    "for cat in categories:\n",
    "    for f in os.listdir(os.path.join(data_dir, cat)):\n",
    "        imgs.append(imgTuple(file=f, img_class=cat, img_dir=os.path.join(data_dir, cat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature-calculating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isColorImg(some_color_func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return some_color_func(*args, **kwargs)\n",
    "        except:\n",
    "            return 0\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.filters import sobel\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "\n",
    "@isColorImg\n",
    "def calc_avgRGB(img_ndarray, color):\n",
    "    \"Calculate pixel average value of one color channel image\"\n",
    "    color_dict={'red':0, 'green':1, 'blue':2}\n",
    "    tmp_img = np.zeros(img_ndarray.shape)\n",
    "    tmp_img[:, :, color_dict[color]] = img_ndarray[:, :, color_dict[color]]\n",
    "    width, height, _ = tmp_img.shape\n",
    "    return np.sum(tmp_img/(width*height))\n",
    "\n",
    "@isColorImg\n",
    "def calc_stdRGB(img_ndarray, color):\n",
    "    \"Calculate standard deviation of one color channel image\"\n",
    "    color_dict={'red':0, 'green':1, 'blue':2}\n",
    "    return np.std(img_ndarray[:, :, color_dict[color]])\n",
    "\n",
    "def calc_colorStd_div(img_ndarray, color, extremum):\n",
    "    \"Calculate segmented standard deviation of a color\"\n",
    "    n_Xdivs = 4\n",
    "    n_Ydivs = 4\n",
    "    stds = np.zeros((n_Xdivs, n_Ydivs))\n",
    "    for i, xBlock in enumerate(np.array_split(list(range(img_ndarray.shape[0])), n_Xdivs)):\n",
    "        for j, yBlock in enumerate(np.array_split(list(range(img_ndarray.shape[1])), n_Ydivs)):\n",
    "            stds[i,j] = calc_stdRGB(img_ndarray[xBlock.min():xBlock.max(), yBlock.min():yBlock.max()], color)\n",
    "    if extremum == 'max':\n",
    "        return np.max(stds)\n",
    "    elif extremum == 'min':\n",
    "        return np.min(stds)\n",
    "    else:\n",
    "        print(f'I don\\'t know the extremum: {extremum}')\n",
    "        return -99\n",
    "\n",
    "@isColorImg\n",
    "def calc_graysclSumAvg(img_ndarray):\n",
    "    \"Calculate pixel average value of grayscale image\"\n",
    "    width, height, _ = img_ndarray.shape\n",
    "    return np.sum(rgb2gray(img_ndarray))/(width*height)\n",
    "\n",
    "def calc_numFASTcorners(img_ndarray):\n",
    "    \"Calculate number of 'features' (corners) using the FAST algorithm\"\n",
    "    # Initiate FAST object with default values\n",
    "    fast = cv2.FastFeatureDetector_create(threshold=100, nonmaxSuppression=True)\n",
    "    kp = fast.detect(img_ndarray, None)\n",
    "    return len(kp)\n",
    "\n",
    "@isColorImg\n",
    "def calc_num_ShiTomasi_corners(img_ndarray):\n",
    "    \"Calculate number of corners above a certain threshold with Shi-Tomasi algorithm\"\n",
    "    corners = cv2.goodFeaturesToTrack(image=cv2.cvtColor(img_ndarray,cv2.COLOR_BGR2GRAY),\n",
    "                                      maxCorners=100, qualityLevel=0.6, minDistance=10)\n",
    "    return len(corners)\n",
    "\n",
    "def calc_meanOfEdgePixelSum(img_ndarray):\n",
    "    \"Really rough calculation of how much of the image is edges\"\n",
    "    edge_sobel = sobel(rgb2gray(img_ndarray))\n",
    "    width, height = edge_sobel.shape\n",
    "    return (100*np.sum(edge_sobel)/(width*height))\n",
    "\n",
    "def calc_numBlobs(img_ndarray, blob_type):\n",
    "    \"How many blobs?\"\n",
    "    gray = rgb2gray(img_ndarray)\n",
    "    if blob_type == 'blobs_dog':\n",
    "        blobs = blob_dog(gray, max_sigma=40, threshold=0.2)\n",
    "    elif blob_type == 'blobs_doh':\n",
    "        blobs = blob_doh(gray, max_sigma=30, threshold=.01)\n",
    "    elif blob_type == 'blobs_log':\n",
    "        blobs = blob_log(gray, min_sigma=10, max_sigma=30, num_sigma=5, threshold=.1)\n",
    "    else:\n",
    "        print(f'I don\\'t know that kind of blob: {blob_type}')\n",
    "        return -99\n",
    "    return len(blobs)\n",
    "\n",
    "@isColorImg\n",
    "def calc_colorCorr(img_ndarray, feature_name):\n",
    "    \"Calculate color correlation\"\n",
    "    color_dict={'red':0, 'green':1, 'blue':2}\n",
    "    if feature_name == 'RG_corr':\n",
    "        c1 = 'red'\n",
    "        c2 = 'green'\n",
    "    elif feature_name == 'GB_corr':\n",
    "        c1 = 'red'\n",
    "        c2 = 'green'\n",
    "    elif feature_name == 'RB_corr':\n",
    "        c1 = 'red'\n",
    "        c2 = 'green'\n",
    "    else:\n",
    "        print(f'I don\\'t know that kind color pair: {feature_name}')\n",
    "        return -99\n",
    "    a = img_ndarray[:, :, color_dict[c1]].flatten()\n",
    "    v = img_ndarray[:, :, color_dict[c2]].flatten()\n",
    "    # Normalize\n",
    "    a = (a - np.mean(a)) / (np.std(a) * len(a))\n",
    "    v = (v - np.mean(v)) /  np.std(v)\n",
    "    return np.correlate(a, v)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to dictionary?\n",
    "def calc_feature(img_ndarray, feature_name):\n",
    "    \n",
    "    # Corners and edges    \n",
    "    if feature_name == 'num_FASTcorners':\n",
    "        return calc_numFASTcorners(img_ndarray)\n",
    "    \n",
    "    elif feature_name == 'num_ShiTomasi_corners':\n",
    "        return calc_num_ShiTomasi_corners(img_ndarray)\n",
    "    \n",
    "    elif feature_name == 'edgeSumAvg':\n",
    "        return calc_meanOfEdgePixelSum(img_ndarray)\n",
    "    \n",
    "    # blobs\n",
    "    elif feature_name in ['blobs_dog', 'blobs_doh', 'blobs_log']:\n",
    "        return calc_numBlobs(img_ndarray, feature_name)\n",
    "      \n",
    "    # circle-find: hough circle transform in skimage\n",
    "    # Daisy\n",
    "    # color cross-correlation\n",
    "    elif feature_name in ['RG_corr', 'GB_corr', 'RB_corr']:\n",
    "        return calc_colorCorr(img_ndarray, feature_name)\n",
    "    \n",
    "    # Simple color channel stuff\n",
    "    elif feature_name == 'avg_R':\n",
    "        return calc_avgRGB(img_ndarray, 'red')\n",
    "    elif feature_name == 'avg_G':\n",
    "        return calc_avgRGB(img_ndarray, 'green')\n",
    "    elif feature_name == 'avg_B':\n",
    "        return calc_avgRGB(img_ndarray, 'blue')\n",
    "    \n",
    "    elif feature_name == 'R_std_total':\n",
    "        return calc_stdRGB(img_ndarray, 'red')\n",
    "    elif feature_name == 'G_std_total':\n",
    "        return calc_stdRGB(img_ndarray, 'green')\n",
    "    elif feature_name == 'B_std_total':\n",
    "        return calc_stdRGB(img_ndarray, 'blue')\n",
    "    \n",
    "    elif feature_name == 'R_std_div_max':\n",
    "        return calc_colorStd_div(img_ndarray, 'red', 'max')\n",
    "    elif feature_name == 'G_std_div_max':\n",
    "        return calc_colorStd_div(img_ndarray, 'green', 'max')\n",
    "    elif feature_name == 'B_std_div_max':\n",
    "        return calc_colorStd_div(img_ndarray, 'blue', 'max')\n",
    "    \n",
    "    elif feature_name == 'R_std_div_min':\n",
    "        return calc_colorStd_div(img_ndarray, 'red', 'min')\n",
    "    elif feature_name == 'G_std_div_min':\n",
    "        return calc_colorStd_div(img_ndarray, 'green', 'min')\n",
    "    elif feature_name == 'B_std_div_min':\n",
    "        return calc_colorStd_div(img_ndarray, 'blue', 'min')\n",
    "    \n",
    "\n",
    "    elif feature_name == 'grayscl_sumAvg':\n",
    "        return calc_graysclSumAvg(img_ndarray)\n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(f'sorry, don\\'t know how to calculate {feature_name}.')\n",
    "        return -99\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally calculate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#dumb features to set up pipeline\n",
    "features = [\n",
    "            # Corners and edges\n",
    "            'num_FASTcorners', 'edgeSumAvg', 'num_ShiTomasi_corners',\n",
    "            # blobs\n",
    "            #'blobs_dog', 'blobs_doh', 'blobs_log',\n",
    "            # color cross-correlation\n",
    "            'RG_corr', 'GB_corr', 'RB_corr',\n",
    "            # Simple color channel stuff\n",
    "            'avg_R', 'avg_G', 'avg_B', 'grayscl_sumAvg',\n",
    "            #'R_std_total', 'G_std_total', 'B_std_total',\n",
    "            'R_std_div_max', 'G_std_div_max', 'B_std_div_max',\n",
    "            'R_std_div_min', 'G_std_div_min', 'B_std_div_min',\n",
    "\n",
    "            # grayscale std_dev?\n",
    "            # hough_circle transform? computationally expensive....\n",
    "            # Daisy - seems complicated\n",
    "           # Investigate fast ICA on categories for feature inspiration?\n",
    "           ]\n",
    "t = time.process_time()\n",
    "df = pd.DataFrame()\n",
    "print('Processing images:')\n",
    "dot_line_thresh = 100\n",
    "count = 0\n",
    "for img in imgs:\n",
    "    this_img_ndarray = io.imread(os.path.join(img.img_dir, img.file))\n",
    "    feature_vals = [img.img_class]\n",
    "    for feature in features:\n",
    "        feature_vals.append(calc_feature(this_img_ndarray, feature))\n",
    "    feature_vals.append(os.path.join(img.img_dir, img.file))\n",
    "    \n",
    "    ddd = ['img_class'] + features + ['full_path']\n",
    "    this_df = pd.DataFrame([feature_vals], index=[img.file],\n",
    "                          columns=['img_class'] + features + ['full_path'])\n",
    "    df = df.append(this_df)\n",
    "    count = count+1\n",
    "    print('.', end = '' if (count%dot_line_thresh) else '\\n')\n",
    "elapsed_time = time.process_time() - t\n",
    "print(f'\\nCalculated {len(features)} features for {len(imgs)} images in {int(elapsed_time*100)/100} s')\n",
    "\n",
    "df.to_pickle('./img_features.pkl')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning from the image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./img_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "X = df.iloc[:,1:-1].values\n",
    "Y = df['img_class']\n",
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important 3 features\n",
      "-------------------------\n",
      "Feature           :   Importance\n",
      "--------------------------------\n",
      "edgeSumAvg        :   0.0811\n",
      "num_FASTcorners   :   0.0775\n",
      "B_std_div_max     :   0.0733\n"
     ]
    }
   ],
   "source": [
    "n_top = 3\n",
    "top_features = (-clf.feature_importances_).argsort()[0:n_top]\n",
    "\n",
    "col_w = 1 + max([len(name) for name in df.columns.values[top_features]])\n",
    "precision = 3\n",
    "print(f'Most important {n_top} features')\n",
    "print('-'*25)\n",
    "print(f'{\"Feature\":<{col_w}}  :   {\"Importance\"}')\n",
    "print('-'*32)\n",
    "for idx in top_features:\n",
    "    print(f'{df.columns.values[idx+1]:<{col_w}}  :   {clf.feature_importances_[idx]:.{precision}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18390805  0.21486643  0.20518868  0.21454112  0.20823245]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, Y, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 10x better than random guessing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the classifier so it can be loaded without calculating all the training image features,\n",
    "# and without training the classifier\n",
    "import pickle\n",
    "\n",
    "fname = \"jaffe_classifier.p\"\n",
    "pickle.dump(clf, open(fname, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to run on validation directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename                 predicted_class       \n",
      "----------------------------------------\n",
      "gorilla_0016.jpg         gorilla               \n",
      "gorilla_0002.jpg         gorilla               \n",
      "gorilla_0003.jpg         gorilla               \n",
      "gorilla_0017.jpg         gorilla               \n",
      "gorilla_0001.jpg         gorilla               \n",
      "gorilla_0015.jpg         gorilla               \n",
      "gorilla_0029.jpg         gorilla               \n",
      "gorilla_0028.jpg         gorilla               \n",
      "gorilla_0014.jpg         gorilla               \n",
      "gorilla_0038.jpg         gorilla               \n",
      "gorilla_0004.jpg         gorilla               \n",
      "gorilla_0010.jpg         gorilla               \n",
      "gorilla_0011.jpg         gorilla               \n",
      "gorilla_0005.jpg         gorilla               \n",
      "gorilla_0039.jpg         gorilla               \n",
      "gorilla_0013.jpg         gorilla               \n",
      "gorilla_0007.jpg         gorilla               \n",
      "gorilla_0006.jpg         gorilla               \n",
      "gorilla_0012.jpg         gorilla               \n",
      "gorilla_0075.jpg         gorilla               \n",
      "gorilla_0061.jpg         gorilla               \n",
      "gorilla_0049.jpg         gorilla               \n",
      "gorilla_0101.jpg         gorilla               \n",
      "gorilla_0115.jpg         gorilla               \n",
      "gorilla_0129.jpg         gorilla               \n",
      "gorilla_0128.jpg         gorilla               \n",
      "gorilla_0114.jpg         gorilla               \n",
      "gorilla_0100.jpg         gorilla               \n",
      "gorilla_0048.jpg         gorilla               \n",
      "gorilla_0060.jpg         gorilla               \n",
      "gorilla_0074.jpg         gorilla               \n",
      "gorilla_0089.jpg         gorilla               \n",
      "gorilla_0062.jpg         gorilla               \n",
      "gorilla_0076.jpg         gorilla               \n",
      "gorilla_0116.jpg         gorilla               \n",
      "gorilla_0102.jpg         gorilla               \n",
      "gorilla_0103.jpg         gorilla               \n",
      "gorilla_0117.jpg         gorilla               \n",
      "gorilla_0077.jpg         gorilla               \n",
      "gorilla_0063.jpg         gorilla               \n",
      "gorilla_0088.jpg         gorilla               \n",
      "gorilla_0098.jpg         horse                 \n",
      "gorilla_0067.jpg         gorilla               \n",
      "gorilla_0073.jpg         gorilla               \n",
      "gorilla_0113.jpg         gorilla               \n",
      "gorilla_0107.jpg         gorilla               \n",
      "gorilla_0106.jpg         gorilla               \n",
      "gorilla_0112.jpg         gorilla               \n",
      "gorilla_0072.jpg         gorilla               \n",
      "gorilla_0066.jpg         gorilla               \n",
      "gorilla_0099.jpg         gorilla               \n",
      "gorilla_0058.jpg         gorilla               \n",
      "gorilla_0070.jpg         gorilla               \n",
      "gorilla_0064.jpg         gorilla               \n",
      "gorilla_0138.jpg         gorilla               \n",
      "gorilla_0104.jpg         gorilla               \n",
      "gorilla_0110.jpg         gorilla               \n",
      "gorilla_0111.jpg         gorilla               \n",
      "gorilla_0105.jpg         gorilla               \n",
      "gorilla_0139.jpg         gorilla               \n",
      "gorilla_0065.jpg         gorilla               \n",
      "gorilla_0071.jpg         gorilla               \n",
      "gorilla_0059.jpg         gorilla               \n",
      "gorilla_0097.jpg         gorilla               \n",
      "gorilla_0083.jpg         gorilla               \n",
      "gorilla_0054.jpg         gorilla               \n",
      "gorilla_0040.jpg         gorilla               \n",
      "gorilla_0068.jpg         gorilla               \n",
      "gorilla_0120.jpg         gorilla               \n",
      "gorilla_0134.jpg         gorilla               \n",
      "gorilla_0108.jpg         gorilla               \n",
      "gorilla_0109.jpg         gorilla               \n",
      "gorilla_0135.jpg         gorilla               \n",
      "gorilla_0121.jpg         gorilla               \n",
      "gorilla_0069.jpg         gorilla               \n",
      "gorilla_0041.jpg         gorilla               \n",
      "gorilla_0055.jpg         gorilla               \n",
      "gorilla_0082.jpg         gorilla               \n",
      "gorilla_0096.jpg         gorilla               \n",
      "gorilla_0080.jpg         gorilla               \n",
      "gorilla_0094.jpg         gorilla               \n",
      "gorilla_0043.jpg         gorilla               \n",
      "gorilla_0057.jpg         gorilla               \n",
      "gorilla_0137.jpg         gorilla               \n",
      "gorilla_0123.jpg         gorilla               \n",
      "gorilla_0122.jpg         gorilla               \n",
      "gorilla_0136.jpg         gorilla               \n",
      "gorilla_0056.jpg         gorilla               \n",
      "gorilla_0042.jpg         gorilla               \n",
      "gorilla_0095.jpg         gorilla               \n",
      "gorilla_0081.jpg         gorilla               \n",
      "gorilla_0085.jpg         airplanes             \n",
      "gorilla_0091.jpg         gorilla               \n",
      "gorilla_0046.jpg         gorilla               \n",
      "gorilla_0052.jpg         gorilla               \n",
      "gorilla_0132.jpg         gorilla               \n",
      "gorilla_0126.jpg         gorilla               \n",
      "gorilla_0127.jpg         gorilla               \n",
      "gorilla_0133.jpg         gorilla               \n",
      "gorilla_0053.jpg         gorilla               \n",
      "gorilla_0047.jpg         gorilla               \n",
      "gorilla_0090.jpg         gorilla               \n",
      "gorilla_0084.jpg         gorilla               \n",
      "gorilla_0092.jpg         gorilla               \n",
      "gorilla_0086.jpg         gorilla               \n",
      "gorilla_0079.jpg         gorilla               \n",
      "gorilla_0051.jpg         gorilla               \n",
      "gorilla_0045.jpg         gorilla               \n",
      "gorilla_0119.jpg         gorilla               \n",
      "gorilla_0125.jpg         gorilla               \n",
      "gorilla_0131.jpg         gorilla               \n",
      "gorilla_0130.jpg         gorilla               \n",
      "gorilla_0124.jpg         gorilla               \n",
      "gorilla_0118.jpg         gorilla               \n",
      "gorilla_0044.jpg         gorilla               \n",
      "gorilla_0050.jpg         gorilla               \n",
      "gorilla_0078.jpg         gorilla               \n",
      "gorilla_0087.jpg         gorilla               \n",
      "gorilla_0093.jpg         gorilla               \n",
      "gorilla_0037.jpg         gorilla               \n",
      "gorilla_0023.jpg         airplanes             \n",
      "gorilla_0022.jpg         gorilla               \n",
      "gorilla_0036.jpg         gorilla               \n",
      "gorilla_0020.jpg         gorilla               \n",
      "gorilla_0034.jpg         gorilla               \n",
      "gorilla_0008.jpg         gorilla               \n",
      "gorilla_0140.jpg         gorilla               \n",
      "gorilla_0141.jpg         gorilla               \n",
      "gorilla_0009.jpg         gorilla               \n",
      "gorilla_0035.jpg         gorilla               \n",
      "gorilla_0021.jpg         gorilla               \n",
      "gorilla_0019.jpg         gorilla               \n",
      "gorilla_0025.jpg         gorilla               \n",
      "gorilla_0031.jpg         gorilla               \n",
      "gorilla_0030.jpg         gorilla               \n",
      "gorilla_0024.jpg         gorilla               \n",
      "gorilla_0018.jpg         gorilla               \n",
      "gorilla_0032.jpg         gorilla               \n",
      "gorilla_0026.jpg         gorilla               \n",
      "gorilla_0027.jpg         gorilla               \n",
      "gorilla_0033.jpg         gorilla               \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from skimage import io\n",
    "\n",
    "clf = pickle.load(open(fname, \"rb\"))\n",
    "\n",
    "def predict_img_class(img_fname):\n",
    "        # Read in image\n",
    "        this_img_ndarray = io.imread(img_fname)\n",
    "        \n",
    "        # Calculate image features\n",
    "        feature_vals = []\n",
    "        for feature in features:\n",
    "            feature_vals.append(calc_feature(this_img_ndarray, feature))\n",
    "        \n",
    "        # Predict class\n",
    "        feature_vals = np.asarray(feature_vals).reshape(1,-1)\n",
    "        prediction = clf.predict(feature_vals)\n",
    "        return prediction[0]\n",
    "\n",
    "\n",
    "\n",
    "def run_final_classifier(dir_path_name):\n",
    "    col_w = 22\n",
    "    print(f'{\"filename\":<{col_w}}   {\"predicted_class\":<{col_w}}')\n",
    "    print('-'*(2*col_w-4))\n",
    "    for f in os.listdir(dir_path_name):\n",
    "        prediction = predict_img_class(os.path.join(dir_path_name, f))\n",
    "        print(f'{f:<{col_w}}   {prediction:<{col_w}}')\n",
    "    \n",
    "    \n",
    "run_final_classifier('../../downloads/hw6_data/gorilla')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
